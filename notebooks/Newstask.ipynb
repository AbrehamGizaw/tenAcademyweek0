{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import re\n",
    "import json\n",
    "import glob\n",
    "import datetime\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Websites with Largest Count of News Articles:\n",
      "source_name\n",
      "ETF Daily News        16746\n",
      "The Times of India     7504\n",
      "GlobeNewswire          5423\n",
      "Globalsecurity.org     3119\n",
      "Forbes                 2784\n",
      "BBC News               2113\n",
      "ABC News               2058\n",
      "Business Insider       2034\n",
      "The Punch              1800\n",
      "Al Jazeera English     1664\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Websites that have the largest count of news articles\n",
    "import pandas as pd\n",
    "# Load data\n",
    "data = pd.read_csv(\"../assets/rating.csv\")\n",
    "\n",
    "# Group by source name and count articles\n",
    "article_counts = data['source_name'].value_counts()\n",
    "\n",
    "# Top 10 websites with the largest count of news articles\n",
    "top_10_articles = article_counts.head(10)\n",
    "print(\"Top 10 Websites with Largest Count of News Articles:\")\n",
    "print(top_10_articles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Websites with Highest Visitor Traffic:\n",
      "Domain\n",
      "toyotamusicfactory.com    1000000\n",
      "soderhomes.com             999999\n",
      "pinkwater.com              999998\n",
      "mt-lock.com                999997\n",
      "kireie.com                 999996\n",
      "keith-baker.com            999995\n",
      "irishcycle.com             999994\n",
      "hmag.com                   999993\n",
      "exploring-africa.com       999992\n",
      "eiretrip.com               999991\n",
      "Name: GlobalRank, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Websites with the highest numbers of visitors traffic\n",
    "traffic_data = pd.read_csv(\"../assets/traffic.csv\")\n",
    "\n",
    "# Group by domain and calculate total traffic\n",
    "traffic_sum = traffic_data.groupby('Domain')['GlobalRank'].sum()\n",
    "\n",
    "# Top 10 websites with the highest traffic\n",
    "top_10_traffic = traffic_sum.nlargest(10)\n",
    "print(\"Top 10 Websites with Highest Visitor Traffic:\")\n",
    "print(top_10_traffic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Countries with Highest Number of News Media Organizations:\n",
      "Country\n",
      "United States     14111\n",
      "United Kingdom     1950\n",
      "Italy              1810\n",
      "France             1041\n",
      "Russia             1024\n",
      "Canada              887\n",
      "Germany             884\n",
      "China               780\n",
      "Turkey              725\n",
      "India               686\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Countries with the highest number of news media organisations (represented by domains in the data)\n",
    "domains_location = pd.read_csv(\"../assets/domains_location.csv\")\n",
    "\n",
    "# Count unique countries\n",
    "country_counts = domains_location['Country'].value_counts()\n",
    "\n",
    "# Top 10 countries with the highest number of news media organizations\n",
    "top_10_countries = country_counts.head(10)\n",
    "print(\"Top 10 Countries with Highest Number of News Media Organizations:\")\n",
    "print(top_10_countries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SourceCommonName', 'location', 'Country'] \n",
      "\n",
      "['article_id', 'source_id', 'source_name', 'author', 'title', 'description', 'url', 'url_to_image', 'published_at', 'content', 'category', 'article', 'title_sentiment'] \n",
      "\n",
      "['GlobalRank', 'TldRank', 'Domain', 'TLD', 'RefSubNets', 'RefIPs', 'IDN_Domain', 'IDN_TLD', 'PrevGlobalRank', 'PrevTldRank', 'PrevRefSubNets', 'PrevRefIPs']\n",
      "0    Pavyllon London, at Four Seasons Hotel London ...\n",
      "1    Nice moved into provisional first place in the...\n",
      "2    The worlds frogs, salamanders, newts and other...\n",
      "3    Iron-rich sediment colors the red-orange water...\n",
      "4    Everything ends. No, Iâ€™m not having an existen...\n",
      "Name: content, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(list(domains_location.columns),'\\n')\n",
    "print(list(data.columns),'\\n')\n",
    "print(list(traffic_data.columns))\n",
    "x = data['content']\n",
    "print(x.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Articles about 'Country Name': 0\n"
     ]
    }
   ],
   "source": [
    "#Countries that have many articles written about them - the content of the news is about that country\n",
    "\n",
    "country_article_counts = data['content'].str.contains('country_name').sum()\n",
    "print(\"Number of Articles about 'Country Name':\", country_article_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Websites Reporting News about 'Country Name':\n",
      "['Forbes' 'GlobeNewswire' 'Deadline' 'ETF Daily News' 'The Punch'\n",
      " 'Business Insider' 'The Times of India' 'Globalsecurity.org' 'ABC News'\n",
      " 'BBC News' 'International Business Times']\n"
     ]
    }
   ],
   "source": [
    "# Assuming the content of the news article contains the country name\n",
    "country_news = data[data['content'].str.contains('Country')]\n",
    "print(\"Websites Reporting News about 'Country Name':\")\n",
    "print(country_news['source_name'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
